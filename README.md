
# ğŸ™ï¸ è¯´è¯äººåˆ†ç¦»è½¬å¤´åƒè§†é¢‘ç”Ÿæˆ (Speaker Diarization to Avatar Video)

---

## ğŸ”„ å·¥ä½œæµç¨‹ flow

![æµç¨‹å›¾](images/flow.png)
---
## ğŸ“º ç¤ºä¾‹ä¸æ¼”ç¤º
- **Bç«™è§†é¢‘æ¼”ç¤º**ï¼š[BV1a3gWzbEq6](https://www.bilibili.com/video/BV1a3gWzbEq6)
- **åœ¨çº¿ä½“éªŒåœ°å€**ï¼š[website](http://010233.xyz)  
  > âš ï¸ **æ³¨æ„ï¼šè¯¥ç½‘ç«™éå¸¸å¼±ï¼Œåªèƒ½å¤„ç† 10 ç§’å·¦å³çš„éŸ³é¢‘**ã€‚

<details>
<summary>ä¸­æ–‡ README</summary>

è¿™æ˜¯ä¸€ä¸ªåŸºäº **[pyannote.audio](https://github.com/pyannote/pyannote-audio)** çš„ Web æ¼”ç¤ºå·¥å…·ï¼Œæ”¯æŒ **éŸ³é¢‘/è§†é¢‘çš„è¯´è¯äººåˆ†ç¦»**ï¼Œå¹¶ç”Ÿæˆå¸¦æœ‰è¯´è¯äººå¤´åƒå¯è§†åŒ–çš„è§†é¢‘ã€‚

---

## âœ¨ åŠŸèƒ½ç‰¹ç‚¹

- **ä¸Šä¼ éŸ³é¢‘/è§†é¢‘**  
  æ”¯æŒ video/* å’Œ audio/wav æ ¼å¼ã€‚
  
- **è¯´è¯äººåˆ†ç¦»**  
  è‡ªåŠ¨è¯†åˆ«éŸ³é¢‘ä¸­çš„è¯´è¯äººï¼Œæˆ–æ‰‹åŠ¨æŒ‡å®šäººæ•°ã€‚

- **å¤´åƒå¯è§†åŒ–**  
  - ä¸ºæ¯ä¸ªè¯´è¯äººä¸Šä¼ å¤´åƒã€‚  
  - å½“æŸä¸ªè¯´è¯äººå‘è¨€æ—¶ï¼Œè§†é¢‘å·¦ä¸Šè§’æ˜¾ç¤ºå¯¹åº”å¤´åƒã€‚  
  - å¤šäººåŒæ—¶å‘è¨€æ—¶ï¼Œå¤´åƒä¼šè‡ªåŠ¨ä¸Šä¸‹æ’åˆ—ã€‚

- **ç”Ÿæˆå¤šç§è§†é¢‘ç‰ˆæœ¬**  
  - **åŠ¨æ€é«˜åº¦ç‰ˆ**  
  - **å›ºå®šåˆ—ç‰ˆ**  
  - **æ¨ªå‘æ’åˆ—ç‰ˆ**  
  - è§†é¢‘èƒŒæ™¯é»˜è®¤é€æ˜ã€‚

---


## ğŸš€ ä½¿ç”¨è¯´æ˜

### 1. ä¸Šä¼ è§†é¢‘/éŸ³é¢‘
- é€‰æ‹©ä¸€ä¸ªè§†é¢‘æˆ–éŸ³é¢‘æ–‡ä»¶ä¸Šä¼ ã€‚
- å¯é€‰å¡« **â€œè¯´è¯äººæ•°â€**ï¼Œè‹¥ç•™ç©ºåˆ™è‡ªåŠ¨æ£€æµ‹ã€‚

### 2. ä¸Šä¼ å¤´åƒå¹¶ç”Ÿæˆè§†é¢‘
- ç³»ç»Ÿä¼šåˆ—å‡ºæ£€æµ‹åˆ°çš„ **è¯´è¯äºº ID**ã€‚
- ä¾æ¬¡ä¸Šä¼ å¯¹åº”çš„å¤´åƒæ–‡ä»¶ã€‚
- ç‚¹å‡» **æäº¤å¤´åƒå¹¶ç”Ÿæˆè§†é¢‘**ã€‚

### 3. é¢„è§ˆç”Ÿæˆçš„è§†é¢‘
- é¡µé¢ä¸‹æ–¹ä¼šå±•ç¤ºä¸åŒç‰ˆæœ¬çš„è§†é¢‘é¢„è§ˆï¼ˆåŠ¨æ€é«˜åº¦ç‰ˆã€å›ºå®šåˆ—ç‰ˆã€æ¨ªå‘æ’åˆ—ç‰ˆï¼‰ã€‚

---

## âš™ï¸ æœ¬åœ°è¿è¡Œ

### 1. å…‹éš†ä»“åº“
```bash
git clone https://github.com/yourname/speaker-diarization-demo.git
cd speaker-diarization-demo
````

### 2. å®‰è£…ä¾èµ–

```bash
python -m venv spk  # æœ€å¥½python3.8ä¸‹è¿è¡Œ, py -3.8 -m venv spk 
spk\Scripts\activate
pip install -r requirement_win.txt
```

### 3. è·å–æ¨¡å‹è®¿é—®æƒé™

1. æ¥å— [pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1) æ¨¡å‹çš„ç”¨æˆ·æ¡æ¬¾ã€‚
2. åœ¨ [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) åˆ›å»º Access Tokenï¼Œå¹¶åœ¨ä»£ç ä¸­ä½¿ç”¨ï¼š

```python
pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1",
                                use_auth_token="Your Access Token")
```

### 4. å¯åŠ¨æœåŠ¡

```bash
python app.py
```

æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼š [http://127.0.0.1:5000](http://127.0.0.1:5000)

> **Windows ç”¨æˆ·**ï¼šå¯ç›´æ¥åŒå‡» 0run.bat å¯åŠ¨ã€‚

---

## ğŸ“Œ TODO

* [ ] æ”¯æŒæ‰‹åŠ¨ç¼–è¾‘è¯´è¯æ—¶é—´æ®µã€‚
* [ ] æ”¯æŒæ‰‹åŠ¨è°ƒæ•´æ¨¡å‹åˆ¤æ–­çš„è¯´è¯äººèº«ä»½ã€‚

---

## ğŸ“œ è®¸å¯è¯

æœ¬é¡¹ç›®ä½¿ç”¨ **MIT License** å¼€æºã€‚

</details>

<details>
<summary>English README</summary>

This is a **web demo based on [pyannote.audio](https://github.com/pyannote/pyannote-audio)** that supports **speaker diarization for audio/video** and generates videos with speaker avatar visualization.

---

## âœ¨ Features

* **Upload Audio/Video**
  Supports video/\* and audio/wav formats.

* **Speaker Diarization**
  Automatically detects speakers in the audio or allows manual specification of the number of speakers.

* **Avatar Visualization**

  * Upload an avatar for each speaker.
  * When a speaker talks, their avatar is displayed at the top-left corner of the video.
  * If multiple speakers talk simultaneously, their avatars are stacked vertically.

* **Multiple Video Versions**

  * **Dynamic Height Version**
  * **Fixed Column Version**
  * **Horizontal Version**
  * Video background is transparent by default.

---

## ğŸ“º Demo

* **Ytb Video**: [demo video](https://www.youtube.com/watch?v=jXeE4_lJL5M)
* **Online Demo**: [website](http://010233.xyz)

  > âš ï¸ **Note: The website is limited and can only process \~10 seconds of audio.**

---



## ğŸš€ How to Use

### 1. Upload Audio/Video

* Choose an audio or video file to upload.
* Optionally fill in **â€œNumber of Speakersâ€**, leave it empty for automatic detection.

### 2. Upload Avatars and Generate Video

* The system will list all detected **speaker IDs**.
* Upload avatar images for each speaker.
* Click **Submit Avatars & Generate Video**.

### 3. Preview the Generated Videos

* Different versions (dynamic height, fixed column, horizontal) will be displayed on the page.

---

## âš™ï¸ Local Setup

### 1. Clone the Repository

```bash
git clone https://github.com/yourname/speaker-diarization-demo.git
cd speaker-diarization-demo
```

### 2. Install Dependencies

```bash
python -m venv spk  # It's recommended to use Python 3.8. py -3.8 -m venv spk 
spk\Scripts\activate
pip install -r requirement_win.txt
```

### 3. Get Model Access Token

1. Accept the user conditions for [pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1).
2. Create an access token at [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) and use it in the code:

```python
pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1",
                                use_auth_token="Your Access Token")
```

### 4. Start the Service

```bash
python app.py
```

Open [http://127.0.0.1:5000](http://127.0.0.1:5000) in your browser.

> **Windows Users**: Simply double-click 0run.bat.

---

## ğŸ“Œ TODO

* [ ] Allow manual editing of speaker time segments.
* [ ] Allow manual adjustment of detected speaker identities.

---

## ğŸ“œ License

This project is released under **MIT License**.

</details>

